{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swash Timestack Tracer\n",
    "This notebook is used to train a regression convolutional network to find the position of the swash front in the middle row of pixels of a snapshot from a timestack. The network structure used is sequential in this code.\n",
    "\n",
    "# Your Task:\n",
    "Train the best convolutional neural network for tracing the swash front. The default structure used is a lightweight network which you can build from. This starting point network is complex enough to converge but struggles with a lot of the edge cases.\n",
    "\n",
    "Code cell 1 imports all the libraries and stores a function used for evaluating your trained model. You don't need to change anything in this code cell.\n",
    "\n",
    "Code cell 2 loads the training images into the notebook and adds any data augmentation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code is modified from a tutorial from sentdex youtube - check out his content, it is really good!\n",
    "\n",
    "# import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import csv\n",
    "\n",
    "# function used to evaluate how good the model is\n",
    "def compare_shoreline(min_uprush, max_uprush, tf_model_version, IMG_SIZE, timestack_name, results_dir):\n",
    "    \n",
    "    folder_name = \"test_timestacks/\"\n",
    "\n",
    "    image_range = max_uprush - min_uprush\n",
    "    \n",
    "    timestack = cv2.imread(folder_name + timestack_name)\n",
    "    timestack_focus = timestack[:, min_uprush:max_uprush]\n",
    "    timestack_labelled = cv2.imread(folder_name + timestack_name + \"_output.png\")\n",
    "    timestack_annotated = timestack_labelled.copy()\n",
    "\n",
    "    height_of_two_peaks = 104 # normally 104 for 2 peaks\n",
    "    # for every row, find the shoreline location (plot as blue dots). If it is a minimum point plot as red Dot, If maximum plot as blue Dot\n",
    "    padding = height_of_two_peaks\n",
    "    height, width, _ = timestack.shape\n",
    "    width = max_uprush - min_uprush\n",
    "    timestack_count = 0\n",
    "\n",
    "    IMG_SIZE_WID = int(IMG_SIZE) # can change this if needed\n",
    "    tf_images = []\n",
    "    tf_model_xc = tf.keras.models.load_model(tf_model_version + \".model\")\n",
    "\n",
    "    vertical_coordinates = []\n",
    "    horizontal_coordinates = []\n",
    "    for i in range(0, int((height - padding)), 1):\n",
    "\n",
    "        horizontal_coordinate = i + int(padding/2)\n",
    "\n",
    "        # get the small section of the image for the horizontal position i\n",
    "        timestack_snapshot = timestack_focus[i:i + padding, :]\n",
    "        title_window_2 = \"Snapshot of timestack used for processing\"\n",
    "\n",
    "        # classify the timestack snapshot through the convolutional neural network for X_coordinate\n",
    "        #tf_images = cv2.cvtColor(timestack_snapshot, cv2.COLOR_BGR2GRAY)   # should have this for gray\n",
    "        tf_images = cv2.resize(timestack_snapshot, (IMG_SIZE_WID, IMG_SIZE))\n",
    "        tf_images_i = np.array(tf_images)\n",
    "        tf_images_i = tf.keras.utils.normalize(tf_images_i, axis=1)\n",
    "        tf_images_i = tf_images_i.reshape(-1, IMG_SIZE, IMG_SIZE_WID, 3)   #should be changed to 1 for gray\n",
    "        prediction = tf_model_xc.predict([tf_images_i])\n",
    "\n",
    "        vertical_coordinate = int((prediction[0])*width) + min_uprush\n",
    "\n",
    "        cv2.circle(timestack_annotated, (vertical_coordinate, horizontal_coordinate), radius=1, color=[255, 0, 0])\n",
    "        vertical_coordinates.append(vertical_coordinate)\n",
    "        horizontal_coordinates.append(horizontal_coordinate)\n",
    "\n",
    "        timestack_count = timestack_count + 1\n",
    "\n",
    "\n",
    "    # get csv values from labelled timestack\n",
    "    manual_csv_points_filename = folder_name + \"runup_data_test\" + timestack_name + \".csv\"\n",
    "    x_vals = []\n",
    "    t_vals = []\n",
    "    with open(manual_csv_points_filename, newline='') as csvfile:\n",
    "        points_reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "        initial_row = 5\n",
    "        initial_row_counter = 0\n",
    "        for row in points_reader:\n",
    "            if initial_row_counter > initial_row:\n",
    "                rows = row[0].split(',')\n",
    "                x_vals.append( int(rows[0][1:-1]) ) # need to remove [] from value and turn into a number\n",
    "                t_vals.append( int(rows[1][1:-1]) ) # need to remove [] from value and turn into a number\n",
    "            initial_row_counter = initial_row_counter + 1\n",
    "\n",
    "    print(\"red is hand picked, green is found by model\")\n",
    "    plt.plot(x_vals, t_vals, color = 'r')\n",
    "    plt.plot(vertical_coordinates, horizontal_coordinates, color = 'g')\n",
    "    plt.gca().invert_yaxis() # invert axis so it is like the timestack image coordinates\n",
    "    plt.show()\n",
    "\n",
    "    #full_stack_window = \"timestack_annotated\"\n",
    "    #cv2.namedWindow(full_stack_window, cv2.WINDOW_NORMAL)\n",
    "    #cv2.resizeWindow(full_stack_window, 1080, 1080)\n",
    "    #cv2.imshow(full_stack_window, timestack_annotated)\n",
    "    #cv2.waitKey()\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "    # find MSE for evey row\n",
    "    SE = []\n",
    "    for i in range(0, len(t_vals), 1):\n",
    "        # make sure the comparison values line up correctly\n",
    "        index_matching = np.where(np.array(horizontal_coordinates) == t_vals[i])\n",
    "        vertical_coordinate_matching = vertical_coordinates[ index_matching[0][0] ]\n",
    "        # /image range normalises the pixel values between 0 and 1\n",
    "        SE.append( ((x_vals[i] - vertical_coordinate_matching)/image_range)**2 )\n",
    "    MSE = np.mean(SE)\n",
    "\n",
    "    # save the image\n",
    "    print(\"saving image\")\n",
    "    cv2.imwrite(results_dir + \"/\" + \"annotated_runup_timestack_\" + timestack_name + \"_\" + tf_model_version + \".png\", timestack_annotated)\n",
    "    \n",
    "    # save the data\n",
    "    print(\"Saving Data to csv file\")\n",
    "\n",
    "    # create csv file\n",
    "    output_data_name = results_dir + \"/\" + \"runup_data_\" + timestack_name + \"_\" + tf_model_version + \".csv\"\n",
    "    with open(output_data_name, 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile)\n",
    "        writer.writerows([[\"timestack shoreline coordinates\"]])\n",
    "\n",
    "    with open(output_data_name, 'a', newline='') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "\n",
    "        time_row = list([\"time (horizontal coordinate)\"])\n",
    "        time_row.extend(horizontal_coordinates)\n",
    "        x_row = list([\"x (vertical coordinate)\"])\n",
    "        x_row.extend(vertical_coordinates)\n",
    "        writer.writerow(time_row)\n",
    "        writer.writerow(x_row)\n",
    "\n",
    "    csvFile.close()\n",
    "\n",
    "    return MSE\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now upload all images. This will take a while since there are a lot! If you enable data manipulations it will take even longer. For training lightweight models it is faster just to upload a fraction of the labelled images, so I have set the for loop to get every 10th image. To process all the images, simply set the for loop range step from 10 to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"%%%%%%%%%%%%%%%%%%%% GET IMAGES %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "# Instead get my own images\n",
    "data = []\n",
    "IMG_SIZE = 64 # should never be above 256 due to image resolution\n",
    "IMG_SIZE_WID = IMG_SIZE # can change this if needed, more simple to keep as square\n",
    "brightness_change = 40 # only necessary if you include data augmentation with brightness variation\n",
    "\n",
    "# first get all images and label accordingly\n",
    "image_names = os.listdir(\"labelled_timestacks\")\n",
    "for i in range(0, len(image_names), 10):\n",
    "    image_i = cv2.imread(\"labelled_timestacks/\" + image_names[i])\n",
    "\n",
    "    # get the image size to be normalized\n",
    "    # we want each snapshot to include approximately 2 swash events, /4 ensures this is the case\n",
    "    height, _, _ = image_i.shape\n",
    "    image_i = image_i[int(height/4):int(height - height/4), :, :] \n",
    "    \n",
    "    resized_image = cv2.resize(image_i, (IMG_SIZE_WID, IMG_SIZE))\n",
    "    Xc = float(image_names[i][23:28]) # this extracts the label of the snapshot, a value from 0 -> 1. \n",
    "    data.append([resized_image, Xc])  # x_coordinate (0-1)\n",
    "    \n",
    "    # You can add these lines if you want to add data augmentation with brightness variation. \n",
    "    # Could be a nice way to simulate sunny and cloudy conditions\n",
    "    \n",
    "    # https://stackoverflow.com/questions/37822375/python-opencv-increasing-image-brightness-without-overflowing-uint8-array\n",
    "    # increase the brightness of image\n",
    "    #resized_image_bi = resized_image.copy()\n",
    "    #resized_image_bi = np.where((255 - resized_image_bi) < brightness_change, 255, resized_image_bi + brightness_change)\n",
    "\n",
    "    # decrease the brightness of image\n",
    "    #resized_image_bd = resized_image.copy()\n",
    "    #resized_image_bd = np.where((resized_image_bd) < brightness_change, 0, resized_image_bd - brightness_change)\n",
    "\n",
    "    #data.append([resized_image_bi, Xc])  # x_coordinate (0-1)\n",
    "    #data.append([resized_image_bd, Xc])  # x_coordinate (0-1)\n",
    "    \n",
    "    # these lines visualize the effect of data augmentation with brightness variation\n",
    "    #cv2.imshow(\"test_a\", resized_image)\n",
    "    #cv2.imshow(\"test_b\", resized_image_bi)\n",
    "    #cv2.imshow(\"test_c\", resized_image_bd)\n",
    "    #cv2.waitKey()\n",
    "\n",
    "    # these if statements add duplicates with brightness augmentations of the labelled maximum and minumum \n",
    "    # swash regions of each swash event. This is a bit of a hack, but seems to help against bias due to most\n",
    "    # of the labelled data being near the middle of snapshots.\n",
    "    if int(image_names[i][29]) == 1:\n",
    "        brightness_increase = cv2.cvtColor(resized_image, cv2.COLOR_BGR2HSV)\n",
    "        brightness_increase[...,2] = np.where((255 - brightness_increase[...,2]) < brightness_change, 255, brightness_increase[...,2] + brightness_change)\n",
    "        brightness_increase = cv2.cvtColor(brightness_increase, cv2.COLOR_HSV2BGR)\n",
    "        data.append([brightness_increase, Xc])\n",
    "\n",
    "        brightness_increase2 = cv2.cvtColor(resized_image, cv2.COLOR_BGR2HSV)\n",
    "        brightness_increase2[...,2] = np.where((255 - brightness_increase2[...,2]) < int(brightness_change/2), 255, brightness_increase2[...,2] + int(brightness_change/2))\n",
    "        brightness_increase2 = cv2.cvtColor(brightness_increase2, cv2.COLOR_HSV2BGR)\n",
    "        data.append([brightness_increase2, Xc])\n",
    "\n",
    "        brightness_decrease = cv2.cvtColor(resized_image, cv2.COLOR_BGR2HSV)\n",
    "        brightness_decrease[...,2] = np.where((brightness_decrease[...,2]) < brightness_change, 0, brightness_decrease[...,2] - brightness_change)\n",
    "        brightness_decrease = cv2.cvtColor(brightness_decrease, cv2.COLOR_HSV2BGR)\n",
    "        data.append([brightness_decrease, Xc])\n",
    "\n",
    "    if int(image_names[i][31]) == 1:\n",
    "        brightness_increase = cv2.cvtColor(resized_image, cv2.COLOR_BGR2HSV)\n",
    "        brightness_increase[...,2] = np.where((255 - brightness_increase[...,2]) < brightness_change, 255, brightness_increase[...,2] + brightness_change)\n",
    "        brightness_increase = cv2.cvtColor(brightness_increase, cv2.COLOR_HSV2BGR)\n",
    "        data.append([brightness_increase, Xc])\n",
    "\n",
    "        brightness_increase2 = cv2.cvtColor(resized_image, cv2.COLOR_BGR2HSV)\n",
    "        brightness_increase2[...,2] = np.where((255 - brightness_increase2[...,2]) < int(brightness_change / 2), 255, brightness_increase2[...,2] + int(brightness_change / 2))\n",
    "        brightness_increase2 = cv2.cvtColor(brightness_increase2, cv2.COLOR_HSV2BGR)\n",
    "        data.append([brightness_increase2, Xc])\n",
    "\n",
    "        brightness_decrease = cv2.cvtColor(resized_image, cv2.COLOR_BGR2HSV)\n",
    "        brightness_decrease[...,2] = np.where((brightness_decrease[...,2]) < brightness_change, 0, brightness_decrease[...,2] - brightness_change)\n",
    "        brightness_decrease = cv2.cvtColor(brightness_decrease, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "        data.append([brightness_decrease, Xc])\n",
    "    \n",
    "    # nice little print statement to track the timing of the image processing\n",
    "    if i % 2000 == 0:\n",
    "        print(i)\n",
    "\n",
    "# randomize rows of data\n",
    "random.shuffle(data)\n",
    "\n",
    "# setup a training set and test set\n",
    "training_test_ratio = 0.85\n",
    "data_train = data[0:int(training_test_ratio*len(data))]\n",
    "data_test = data[int(training_test_ratio*len(data)):]\n",
    "\n",
    "# split x data from y data\n",
    "x_train = np.array(list(map(list, zip(*data_train)))[0])\n",
    "y_train = np.array(list(map(list, zip(*data_train)))[1])\n",
    "\n",
    "# needs to all be numpy arrays to work in tensorflow\n",
    "x_test = np.array(list(map(list, zip(*data_test)))[0])\n",
    "x_test_show = x_test # keep a copy for visualization later\n",
    "y_test = np.array(list(map(list, zip(*data_test)))[1])\n",
    "\n",
    "# normalize input features (which are the pixel values)\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "# reshape for convolutional compatability\n",
    "x_train = x_train.reshape(-1, IMG_SIZE, IMG_SIZE_WID, 3) # 3 is for the 3 colour channels\n",
    "x_test = x_test.reshape(-1, IMG_SIZE, IMG_SIZE_WID, 3)\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you are ready to do some training. The model architecture I have setup is VGGnet style. One of the coolest things about VGGnet is the consecutive 3x3 convolutional layers before max pooling. \"a stack of two\n",
    "3×3 conv. layers (without spatial pooling in between) has an effective receptive field of 5×5\", have a read of the paper yourself (https://arxiv.org/abs/1409.1556). There are many hyperparameters you can change such as the depth, width of layers, activation functions, max pooling layers (pool size and stride), convolutional layer sizes, optimizer, batch size, epochs, etc. \n",
    "\n",
    "Because this is a regression application it is hard to properly evaluate performance of the model without a seperate test set. After the model is trained, there is code which will evaluate performance by comparing with test swash timestacks. This works by finding the square of the horizontal distance between the model estimated points and manually traced points and then dividing by the total number of points compared (e.g. the mean squared error).\n",
    "\n",
    "Even though it will feel like watching paint dry, watching the loss change as the model trains will give you a good idea if the model converges and how it converges. If the model gets stuck and doesn't decrease at all then you might need to increase the batch size or reduce the architecture size or image size. A better alternative to watching paint dry is probably to produce some learning curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"%%%%%%%%%%%%%%%%%%%% MACHINE LEARNING %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "# Every time you train a model, change the name below. \n",
    "# It is also good practice to record all hyperparameters you used and the performance \n",
    "# of each model trained. Then you can look through all your results and learn something.\n",
    "tf_model_version = \"test_0\"\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), input_shape = x_train.shape[1:]))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding=\"SAME\"))\n",
    "\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding=\"SAME\"))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Dense(256))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('linear'))\n",
    "\n",
    "# This line is if you want to use the GPU. The model.compile and model.fit lines need to be in the with statement.\n",
    "#with tf.device('/gpu:0'):\n",
    "\n",
    "\n",
    "# accuracy metric is not useful, but without it the evaluate section doesn't work\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"adam\", metrics=['accuracy'])\n",
    "model.fit(x_train, y_train, batch_size=32, validation_split=0.1, epochs=10)\n",
    "\n",
    "model.summary() # should always check this to make sure your architecture is a good size. If your sizes reduce to 1x1 too early, deeper layers are not very effective!\n",
    "\n",
    "\"\"\"%%%%%%%%%%%%%%%%%%%% EVALUATION %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\"\"\"\n",
    "\n",
    "# validation loss and validation accuracy should be close to training loss and accuracy (otherwise overfitting!)\n",
    "train_loss, train_acc = model.evaluate(x_train, y_train)\n",
    "val_loss, val_acc = model.evaluate(x_test, y_test)\n",
    "\n",
    "print(\"training loss = \" + str(train_loss) + \", training accuracy = \" + str(train_acc))\n",
    "print(\"test loss     = \" + str(val_loss) + \", test accuracy     = \" + str(val_acc))\n",
    "\n",
    "model.save(tf_model_version + \".model\")\n",
    "\n",
    "predictions = model.predict([x_test])\n",
    "\n",
    "# plot graphs inside the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# make a new directory for results\n",
    "current_path = os.getcwd()\n",
    "results_dir = tf_model_version\n",
    "results_dir_path = os.path.join(current_path, results_dir)\n",
    "if os.path.exists(results_dir_path):\n",
    "    shutil.rmtree(results_dir_path)\n",
    "    print(\"old results directory removed\")\n",
    "os.mkdir(results_dir_path)\n",
    "print(\"new results directory created called \" + results_dir)\n",
    "\n",
    "# don't change the min_uprush and max_uprush values, \n",
    "# these are fixed values according to the labelled evaluation timestacks\n",
    "error_list = []\n",
    "timestack_name = \"20101109084810_02_25ppm_test_s.png\" # 194 and 925\n",
    "min_uprush = 194\n",
    "max_uprush = 925\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, tf_model_version, IMG_SIZE, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "timestack_name = \"20101110094203_05_25ppm_test_s.png\" # 40 and 580\n",
    "min_uprush = 40\n",
    "max_uprush = 580\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, tf_model_version, IMG_SIZE, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "timestack_name = \"20101111092821_01_25ppm_test_s.png\" # 116 and 800\n",
    "min_uprush = 116\n",
    "max_uprush = 800\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, tf_model_version, IMG_SIZE, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "timestack_name = \"OneMile8_test_s.png\" # 77 and 289\n",
    "min_uprush = 77\n",
    "max_uprush = 289\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, tf_model_version, IMG_SIZE, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "timestack_name = \"FC4_test_s.png\" # 37 and 240\n",
    "min_uprush = 37\n",
    "max_uprush = 240\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, tf_model_version, IMG_SIZE, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "print(\"\\nMSE summary for all timestacks:\")\n",
    "print(\"20101109084810_02_25ppm_test_s.png\" + \" \" + str(error_list[0]))\n",
    "print(\"20101110094203_05_25ppm_test_s.png\" + \" \" + str(error_list[1]))\n",
    "print(\"20101111092821_01_25ppm_test_s.png\" + \" \" + str(error_list[2]))\n",
    "print(\"OneMile8_test_s.png               \" + \" \" + str(error_list[3]))\n",
    "print(\"FC4_test_s.png                    \" + \" \" + str(error_list[4]))\n",
    "\n",
    "print(\"\\nAverage MSE for all seen timestacks = \" + str(np.mean(error_list)))\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now visualize your results in the results directory. You can run the below cell to see what my best results were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_model = \"michaelThompson_imgSize_64\"\n",
    "\n",
    "# make a new directory\n",
    "current_path = os.getcwd()\n",
    "results_dir = mt_model\n",
    "results_dir_path = os.path.join(current_path, results_dir)\n",
    "if os.path.exists(results_dir_path):\n",
    "    shutil.rmtree(results_dir_path)\n",
    "    print(\"old results directory removed\")\n",
    "os.mkdir(results_dir_path)\n",
    "print(\"new results directory created called \" + results_dir)\n",
    "\n",
    "# don't change the min_uprush and max_uprush values, \n",
    "# these are fixed values according to the labelled evaluation timestacks\n",
    "error_list = []\n",
    "timestack_name = \"20101109084810_02_25ppm_test_s.png\" # 194 and 925\n",
    "min_uprush = 194\n",
    "max_uprush = 925\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, mt_model, IMG_SIZE, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "timestack_name = \"20101110094203_05_25ppm_test_s.png\" # 40 and 580\n",
    "min_uprush = 40\n",
    "max_uprush = 580\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, mt_model, IMG_SIZE, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "timestack_name = \"20101111092821_01_25ppm_test_s.png\" # 116 and 800\n",
    "min_uprush = 116\n",
    "max_uprush = 800\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, mt_model, IMG_SIZE, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "timestack_name = \"OneMile8_test_s.png\" # 77 and 289\n",
    "min_uprush = 77\n",
    "max_uprush = 289\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, mt_model, IMG_SIZE, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "timestack_name = \"FC4_test_s.png\" # 37 and 240\n",
    "min_uprush = 37\n",
    "max_uprush = 240\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, mt_model, IMG_SIZE, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "print(\"\\nMSE summary for all timestacks:\")\n",
    "print(\"20101109084810_02_25ppm_test_s.png\" + \" \" + str(error_list[0]))\n",
    "print(\"20101110094203_05_25ppm_test_s.png\" + \" \" + str(error_list[1]))\n",
    "print(\"20101111092821_01_25ppm_test_s.png\" + \" \" + str(error_list[2]))\n",
    "print(\"OneMile8_test_s.png               \" + \" \" + str(error_list[3]))\n",
    "print(\"FC4_test_s.png                    \" + \" \" + str(error_list[4]))\n",
    "\n",
    "print(\"\\nAverage MSE for all seen timestacks = \" + str(np.mean(error_list)))\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to use a GPU, this code is helpful to check that it will work. It can be a bit of a pain to set it up in anaconda, but the efficiency is worth it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available(\n",
    "    cuda_only=False,\n",
    "    min_cuda_compute_capability=None\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

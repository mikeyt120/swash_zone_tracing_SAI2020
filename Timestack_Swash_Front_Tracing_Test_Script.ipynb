{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the tf model and test_timestacks folder are in your working directory. Then simply run the code and check the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import csv\n",
    "from scipy.stats import norm\n",
    "\n",
    "tf_model_version = \"example\" # name of tf model folder\n",
    "IMG_SIZE = 256\n",
    "IMG_SIZE_WID = 512\n",
    "\n",
    "# https://stackoverflow.com/questions/22579434/python-finding-the-intersection-point-of-two-gaussian-curves\n",
    "def solve(m1,m2,std1,std2):\n",
    "    a = 1/(2*std1**2) - 1/(2*std2**2)\n",
    "    b = m2/(std2**2) - m1/(std1**2)\n",
    "    c = m1**2 /(2*std1**2) - m2**2 / (2*std2**2) - np.log(std2/std1)\n",
    "    return np.roots([a,b,c])\n",
    "\n",
    "# function used to evaluate how good the model is\n",
    "def compare_shoreline(min_uprush, max_uprush, tf_model_version, IMG_SIZE, IMG_SIZE_WID, timestack_name, results_dir):\n",
    "    \n",
    "    folder_name = \"test_timestacks/\"\n",
    "    \n",
    "    image_range = max_uprush - min_uprush\n",
    "    \n",
    "    timestack = cv2.imread(folder_name + timestack_name)\n",
    "    timestack_focus = timestack[:, min_uprush:max_uprush]\n",
    "    timestack_labelled = cv2.imread(folder_name + timestack_name + \"_output.png\")\n",
    "    timestack_annotated = timestack_labelled.copy()\n",
    "    mask_annotated = cv2.imread(folder_name + timestack_name + \"_output.png\", cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    timestack_count = 0\n",
    "\n",
    "    tf_images = []\n",
    "    if tf_model_version == \"michaelThompson_imgSize_64\":\n",
    "        # this way of reading/saving models worked for an older version of tensorflow 2.x\n",
    "        tf_model_xc = tf.keras.models.load_model(tf_model_version + \".model\")\n",
    "    else:\n",
    "        tf_model_xc = tf.keras.models.load_model(tf_model_version + \"_model\")\n",
    "\n",
    "    vertical_coordinates = []\n",
    "    horizontal_coordinates = []\n",
    "    full_height, full_width, _ = timestack_focus.shape\n",
    "    snap_width = full_width\n",
    "    snap_height = int(full_width*(IMG_SIZE/IMG_SIZE_WID)) # make sure this matches CNN model input ratio\n",
    "    max_snap_start = full_height - snap_height\n",
    "    snap_start = 0\n",
    "    snap_counter = 0\n",
    "    # split the image up into square sections - overlap the last section\n",
    "    while snap_start < max_snap_start:\n",
    "\n",
    "        # get square image\n",
    "        snapshot = timestack_focus[snap_start:(snap_start + snap_height)]\n",
    "        \n",
    "        # prepare as tf input\n",
    "        snapshot_resize = cv2.resize(snapshot, (IMG_SIZE, IMG_SIZE_WID))\n",
    "        snapshot_resize_nm = np.array(snapshot_resize) / 255\n",
    "        snapshot_input = snapshot_resize_nm.reshape(-1, IMG_SIZE, IMG_SIZE_WID, 3)\n",
    "        \n",
    "        \n",
    "        ####### Prepare image correctly for model\n",
    "\n",
    "        # put into model\n",
    "        mask_test = tf_model_xc.predict([snapshot_input])[0]\n",
    "        mask_test = cv2.resize(mask_test, (snap_width, snap_height))\n",
    "        # get rid of second channel as it is simply 1 - first channel\n",
    "        mask_test = mask_test[:, :, 0]\n",
    "\n",
    "        # add mask to mask image\n",
    "        mask_annotated[snap_start:(snap_start + snap_height), min_uprush:max_uprush] = mask_test * 255\n",
    "        \n",
    "        # apply light and dark gaussian interesection method to extract shoreline points\n",
    "        # use something similar to Otsu's method for each row to draw a boundary line\n",
    "        for j in range(0, len(mask_test), 1):\n",
    "            pixel_row = mask_test[j]\n",
    "\n",
    "            light_pixels = []\n",
    "            dark_pixels = []\n",
    "            for k in range(0, len(pixel_row), 1):\n",
    "                if pixel_row[k] >= 0.5:\n",
    "                    light_pixels.extend([k]*int(pixel_row[k]*255))\n",
    "                else:\n",
    "                    dark_pixels.extend([k]*int((0.5 - pixel_row[k])*255))\n",
    "\n",
    "            # find mean and variance of pixels\n",
    "            light_mean, light_std = norm.fit(light_pixels)\n",
    "            dark_mean, dark_std = norm.fit(dark_pixels)\n",
    "\n",
    "            try:\n",
    "                # get the interect of both gaussians\n",
    "                intersect_i = solve(light_mean, dark_mean, light_std, dark_std)\n",
    "\n",
    "                # if intersect has more than 1 point, choose the point closest to the middle of the two means\n",
    "                if len(intersect_i) == 2:\n",
    "                    mean_middle = (light_mean + dark_mean)/2\n",
    "                    intersect = min(intersect_i, key=lambda x:abs(x-mean_middle))\n",
    "                # if 1 point thats great!\n",
    "                elif len(intersect_i) == 1:\n",
    "                    intersect = intersect_i\n",
    "                # if 0 or 3 or more points, simply choose middle of two means\n",
    "                else:\n",
    "                    intersect = (light_mean + dark_mean)/2\n",
    "            except:\n",
    "                # just use middle of means\n",
    "                if np.isnan(light_mean) or np.isnan(dark_mean):\n",
    "                    intersect = 0\n",
    "                else:\n",
    "                    intersect = (light_mean + dark_mean)/2\n",
    "            \n",
    "            # annotate over timestack\n",
    "            cv2.circle(timestack_annotated, (min_uprush + int(intersect), snap_start + j), 1, (255, 0, 0))\n",
    "            \n",
    "            # save vertical and horizontal coordinates for comparison with labels.\n",
    "            horizontal_coordinates.append(snap_start + j)\n",
    "            vertical_coordinates.append(min_uprush + int(intersect))\n",
    "        \n",
    "        timestack_count = timestack_count + 1\n",
    "        snap_start = snap_start + int(snap_height)\n",
    "        snap_counter = snap_counter + 1\n",
    "    \n",
    "    snap_end = snap_counter*snap_height\n",
    "    # after while loop is finished, do one final snapshot that overlaps with last snapshot till the end.\n",
    "    # get square image\n",
    "    snapshot = timestack_focus[(full_height - snap_height):full_height]\n",
    "\n",
    "    # prepare as tf input\n",
    "    snapshot_resize = cv2.resize(snapshot, (IMG_SIZE, IMG_SIZE_WID))\n",
    "    snapshot_resize_nm = np.array(snapshot_resize) / 255\n",
    "    snapshot_input = snapshot_resize_nm.reshape(-1, IMG_SIZE, IMG_SIZE_WID, 3)\n",
    "\n",
    "    # put into model\n",
    "    mask_test = tf_model_xc.predict([snapshot_input])[0]\n",
    "    mask_test = cv2.resize(mask_test, (snap_width, snap_height))\n",
    "    # get rid of second channel as it is simply 1 - first channel\n",
    "    mask_test = mask_test[:, :, 0]\n",
    "    \n",
    "    # add mask to mask image\n",
    "    mask_annotated[(full_height - snap_height):full_height, min_uprush:max_uprush] = mask_test * 255\n",
    "    \n",
    "    # apply light and dark gaussian interesection method to extract shoreline points\n",
    "    # use something similar to otsu's method for each row to draw a boundary line\n",
    "    for j in range(0, len(mask_test), 1):\n",
    "        pixel_row = mask_test[j]\n",
    "\n",
    "        light_pixels = []\n",
    "        dark_pixels = []\n",
    "        for k in range(0, len(pixel_row), 1):\n",
    "            if pixel_row[k] >= 0.5:\n",
    "                light_pixels.extend([k]*int(pixel_row[k]*255))\n",
    "            else:\n",
    "                dark_pixels.extend([k]*int((0.5 - pixel_row[k])*255))\n",
    "\n",
    "        # find mean and variance of pixels\n",
    "        light_mean, light_std = norm.fit(light_pixels)\n",
    "        dark_mean, dark_std = norm.fit(dark_pixels)\n",
    "\n",
    "        try:\n",
    "            # get the interect of both gaussians\n",
    "            intersect_i = solve(light_mean, dark_mean, light_std, dark_std)\n",
    "            \n",
    "            # if intersect has more than 1 point, choose the point closest to the middle of the two means\n",
    "            if len(intersect_i) == 2:\n",
    "                mean_middle = (light_mean + dark_mean)/2\n",
    "                intersect = min(intersect_i, key=lambda x:abs(x-mean_middle))\n",
    "            # if 1 point thats great!\n",
    "            elif len(intersect_i) == 1:\n",
    "                intersect = intersect_i\n",
    "            # if 0 or 3 or more points, simply choose middle of two means\n",
    "            else:\n",
    "                intersect = (light_mean + dark_mean)/2\n",
    "        except:\n",
    "            # just use middle of means\n",
    "            if np.isnan(light_mean) or np.isnan(dark_mean):\n",
    "                intersect = 0\n",
    "            else:\n",
    "                intersect = (light_mean + dark_mean)/2\n",
    "        \n",
    "        # only add to timestack and data if new data\n",
    "        if (full_height - snap_height + j) >= snap_end:\n",
    "            # annotate over timestack\n",
    "            cv2.circle(timestack_annotated, (min_uprush + int(intersect), full_height - snap_height + j), 1, (255, 0, 0))\n",
    "\n",
    "            # save vertical and horizontal coordinates for comparison with labels.\n",
    "            horizontal_coordinates.append(full_height - snap_height + j)\n",
    "            vertical_coordinates.append(min_uprush + int(intersect))\n",
    "        \n",
    "    # get csv values from labelled timestack\n",
    "    manual_csv_points_filename = folder_name + \"runup_data_test\" + timestack_name + \".csv\"\n",
    "    x_vals = []\n",
    "    t_vals = []\n",
    "    with open(manual_csv_points_filename, newline='') as csvfile:\n",
    "        points_reader = csv.reader(csvfile, delimiter=' ', quotechar='|')\n",
    "        initial_row = 5\n",
    "        initial_row_counter = 0\n",
    "        for row in points_reader:\n",
    "            if initial_row_counter > initial_row:\n",
    "                rows = row[0].split(',')\n",
    "                x_vals.append( int(rows[0][1:-1]) ) # need to remove [] from value and turn into a number\n",
    "                t_vals.append( int(rows[1][1:-1]) ) # need to remove [] from value and turn into a number\n",
    "            initial_row_counter = initial_row_counter + 1\n",
    "\n",
    "    print(\"red is hand picked, green is found by model\")\n",
    "    plt.plot(x_vals, t_vals, color = 'r')\n",
    "    plt.plot(vertical_coordinates, horizontal_coordinates, color = 'g')\n",
    "    plt.gca().invert_yaxis() # invert axis so it is like the timestack image coordinates\n",
    "    plt.show()\n",
    "\n",
    "    #full_stack_window = \"timestack_annotated\"\n",
    "    #cv2.namedWindow(full_stack_window, cv2.WINDOW_NORMAL)\n",
    "    #cv2.resizeWindow(full_stack_window, 1080, 1080)\n",
    "    #cv2.imshow(full_stack_window, timestack_annotated)\n",
    "    #cv2.waitKey()\n",
    "    #cv2.destroyAllWindows()\n",
    "\n",
    "    # find MSE for evey row\n",
    "    SE = []\n",
    "    for i in range(0, len(t_vals), 1):\n",
    "        # make sure the comparison values line up correctly\n",
    "        index_matching = np.where(np.array(horizontal_coordinates) == t_vals[i])\n",
    "        vertical_coordinate_matching = vertical_coordinates[ index_matching[0][0] ]\n",
    "        # /image range normalises the pixel values between 0 and 1\n",
    "        SE.append( ((x_vals[i] - vertical_coordinate_matching)/image_range)**2 )\n",
    "    MSE = np.mean(SE)\n",
    "\n",
    "    # save the image\n",
    "    print(\"saving image\")\n",
    "    cv2.imwrite(results_dir + \"/\" + \"annotated_runup_timestack_\" + timestack_name + \"_\" + tf_model_version + \".png\", timestack_annotated)\n",
    "    \n",
    "    # save the image\n",
    "    print(\"saving mask\")\n",
    "    cv2.imwrite(results_dir + \"/\" + \"mask_output_timestack_\" + timestack_name + \"_\" + tf_model_version + \".png\", mask_annotated)\n",
    "    \n",
    "    # save the data\n",
    "    print(\"Saving Data to csv file\")\n",
    "\n",
    "    # create csv file\n",
    "    output_data_name = results_dir + \"/\" + \"runup_data_\" + timestack_name + \"_\" + tf_model_version + \".csv\"\n",
    "    with open(output_data_name, 'w') as writeFile:\n",
    "        writer = csv.writer(writeFile)\n",
    "        writer.writerows([[\"timestack shoreline coordinates\"]])\n",
    "\n",
    "    with open(output_data_name, 'a', newline='') as csvFile:\n",
    "        writer = csv.writer(csvFile)\n",
    "\n",
    "        time_row = list([\"time (horizontal coordinate)\"])\n",
    "        time_row.extend(horizontal_coordinates)\n",
    "        x_row = list([\"x (vertical coordinate)\"])\n",
    "        x_row.extend(vertical_coordinates)\n",
    "        writer.writerow(time_row)\n",
    "        writer.writerow(x_row)\n",
    "\n",
    "    csvFile.close()\n",
    "\n",
    "    return MSE\n",
    "\n",
    "# plot graphs inside the notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# make a new directory for results\n",
    "current_path = os.getcwd()\n",
    "results_dir = tf_model_version\n",
    "results_dir_path = os.path.join(current_path, results_dir)\n",
    "if os.path.exists(results_dir_path):\n",
    "    shutil.rmtree(results_dir_path)\n",
    "    print(\"old results directory removed\")\n",
    "os.mkdir(results_dir_path)\n",
    "print(\"new results directory created called \" + results_dir)\n",
    "\n",
    "# don't change the min_uprush and max_uprush values, \n",
    "# these are fixed values according to the labelled evaluation timestacks\n",
    "error_list = []\n",
    "timestack_name = \"20101109084810_02_25ppm_test_s.png\" # 194 and 925\n",
    "min_uprush = 194\n",
    "max_uprush = 925\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, tf_model_version, IMG_SIZE, IMG_SIZE_WID, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "timestack_name = \"20101110094203_05_25ppm_test_s.png\" # 40 and 580\n",
    "min_uprush = 40\n",
    "max_uprush = 580\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, tf_model_version, IMG_SIZE, IMG_SIZE_WID, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "timestack_name = \"20101111092821_01_25ppm_test_s.png\" # 116 and 800\n",
    "min_uprush = 116\n",
    "max_uprush = 800\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, tf_model_version, IMG_SIZE, IMG_SIZE_WID, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "timestack_name = \"OneMile8_test_s.png\" # 77 and 289\n",
    "min_uprush = 77\n",
    "max_uprush = 289\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, tf_model_version, IMG_SIZE, IMG_SIZE_WID, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "timestack_name = \"FC4_test_s.png\" # 37 and 240\n",
    "min_uprush = 37\n",
    "max_uprush = 240\n",
    "ground_truth_error = compare_shoreline(min_uprush, max_uprush, tf_model_version, IMG_SIZE, IMG_SIZE_WID, timestack_name, results_dir)\n",
    "print(\"MSE for \" + timestack_name + \" is \" + str(ground_truth_error))\n",
    "error_list.append(ground_truth_error)\n",
    "\n",
    "print(\"\\nMSE summary for all timestacks:\")\n",
    "print(\"20101109084810_02_25ppm_test_s.png\" + \" \" + str(error_list[0]))\n",
    "print(\"20101110094203_05_25ppm_test_s.png\" + \" \" + str(error_list[1]))\n",
    "print(\"20101111092821_01_25ppm_test_s.png\" + \" \" + str(error_list[2]))\n",
    "print(\"OneMile8_test_s.png               \" + \" \" + str(error_list[3]))\n",
    "print(\"FC4_test_s.png                    \" + \" \" + str(error_list[4]))\n",
    "\n",
    "print(\"\\nAverage MSE for all seen timestacks = \" + str(np.mean(error_list)))\n",
    "\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
